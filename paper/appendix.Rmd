---
title: |
  Appendix: Automated assessment of residual plots with computer vision models
type: Draft paper (Incomplete)
author:
  - name: Weihao Li
    affil: a
    email: weihao.li@monash.edu
  - name: Dianne Cook
    affil: a
    email: dicook@monash.edu
  - name: Emi Tanaka
    affil: b, c
    email: emi.tanaka@anu.edu.au
  - name: Susan VanderPlas
    affil: d
    email: susan.vanderplas@unl.edu
  - name: Klaus Ackermann
    affil: a
    email: Klaus.Ackermann@monash.edu
affiliation:
  - num: a
    address: |
      Department of Econometrics and Business Statistics, Monash University, Clayton, VIC, Australia
  - num: b
    address: |
      Biological Data Science Institute, Australian National University, Acton, ACT, Australia
  - num: c
    address: |
      Research School of Finance, Actuarial Studies and Statistics, Australian National University, Acton, ACT, Australia
  - num: d
    address: |
      Department of Statistics, University of Nebraska, Lincoln, Nebraska, USA
bibliography: ref.bib
abstract: |
  TBD.
keywords: |
  TBD
header-includes: |
  \usepackage{lscape}
  \usepackage{hyperref}
  \usepackage[utf8]{inputenc}
  \def\tightlist{}
  \usepackage{setspace}
  \doublespacing
output: rticles::tf_article
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE, 
  warning = FALSE, 
  echo = FALSE,
  fig.width = 8,
  fig.height = 6,
  out.width = "100%",
  fig.align = "center")
```

# Additional details about data generation

## Computation of scagnostics

In Section \ref{introduction}, we mentioned that scagnostics consist of a set of manually designed visual feature extraction functions. While our computer vision model will learn its own feature extraction function during training, leveraging additional information from scagnostics can enhance the model's predictive accuracy.

For each generated residual plot, we computed four scagnostics – "Monotonic," "Sparse," "Splines," and "Striped" – using the `cassowaryr` R package [@mason2022cassowaryr]. These computed measures, along with the number of observations from the fitted model, were provided as the second input for the computer vision model. Although other scagnostics are informative, they are currently unavailable due to a fatal bug in the compiled C program of the `interp` R package [@Albrecht2023interp], which may unpredictably crash the process. For reproducibility, we excluded these scagnostics from the training data.

# Neural Network Layers Used in the Study

This study employs seven types of neural network layers, all of which are standard components frequently found in modern deep learning models. These layers are well-documented in textbooks like @goodfellow2016deep, which offer thorough explanations and mathematical insights. In this section, we will offer a concise overview of these layers, drawing primarily from the insights provided in @goodfellow2016deep.

## Dense Layer

The Dense layer, also known as the fully-connected layer, is the fundamental unit in neural networks. It conducts a matrix multiplication operation between the input matrix $\boldsymbol{X}$ and a weight matrix $\boldsymbol{W}$ to generate the output matrix $\boldsymbol{O}$, which can be written as

$$\boldsymbol{O} = \boldsymbol{X}\boldsymbol{W} + b,$$

where $b$ is the intercept.

## ReLu Layer

The ReLU layer, short for rectified linear unit, is an element-wise non-linear function introduced by @nair2010rectified. It sets the output elements to zero if the corresponding input element is negative; otherwise, it retains the original input. Mathematically, it can be expressed as:

$$\boldsymbol{O}(i,j) = max\{0, \boldsymbol{X}(i,j)\},$$

where $\boldsymbol{O}(i,j)$ is the $i$th row and $j$th column entry of matrix $\boldsymbol{O}$, and $\boldsymbol{X}(i,j)$ is the $i$th row and $j$th column entry of matrix $\boldsymbol{X}$.

## Convolutaional Layer

In Dense layers, matrix multiplication leads to each output unit interacting with every input unit, whereas convolutional layers operate differently with sparse interactions. Here, an output unit in a convolutional layer is connected solely to a subset of input units, and the weight is shared across all input units. Achieving this involves using a kernel, typically a small square matrix, to conduct matrix multiplication across all input units. Precisely, this concept can be formulated as:

$$O(i, j) = \sum_m\sum_nI(i - m, j - n)K(m, n),$$

where $m$ and $n$ are the row and columns indices of the kernel $K$. 

If there are multiple kernels used in one covolutional layer, then each kernel will have its own weights and the output will be a three-dimensional tensor, where the length of the third channel is the number of kernels. 

## Pooling Layer

A pooling layer substitutes the input at a specific location with a summary statistic derived from nearby input units. Typically, there are two types of pooling layers: max pooling and average pooling. Max pooling computes the maximum value within a rectangular neighborhood, while average pooling calculates their average. Pooling layers helps making the representation approximately invariant to minor translations of the input. The output matrix of a pooling layer is approximately $s$ times smaller than the input matrix, where $s$ represents the length of the rectangular area. This can be formulated as:

$$O(i, j) = \underset{m,n}{\max} I(si + m,sj+n).$$

## Global Pooling Layer

A global pooling layer condenses an input matrix into a scalar value by either extracting the maximum or computing the average across all elements. This layer acts as a crucial link between the convolutional structure and the subsequent dense layers in a neural network architecture. When convolutional layers utilize multiple kernels, the output becomes a three-dimensional tensor with numerous channels. In this scenario, the global pooling layer treats each channel individually, much like distinct features in a conventional classifier. This approach facilitates the extraction of essential features from complex data representations, enhancing the network's ability to learn meaningful patterns.

## Batch Normalization Layer



## Dropout Layer

<!-- ## visualize the convolutional blocks -->


